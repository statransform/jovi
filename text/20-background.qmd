## Background {#background}
We provide background on the history, scope, construction, and use of rank transformation methods, with a particular focus on ART. Additionally, we summarize the results of previous evaluation studies and position our own work within this context. 

### Nonparametric statistical tests
A common assumption of ANOVAs and linear regression is that the distribution of residuals is normal. More technically, the normality assumption concerns the sampling distribution of the mean. Therefore, when sample sizes are sufficiently large, these methods are robust to departures from the normality assumption because the sampling distribution of the mean is asymptotically normal, regardless of the shape of the population distributions (Central Limit Theorem). However, their accuracy drops if samples are relatively small and populations markedly deviate from normal. 

The goal of *nonparametric* procedures is to address this problem by making fewer or no assumptions about the underlying distributions. The original idea of replacing the data values by their ranks belongs to @spearman1904. The key advantage of ranks is that they preserve the monotonic relationship of values while also allowing the derivation of an exact probability distribution. This probability distribution can then be used for statistical inference, such as calculating a *p*-value. The idea of using ranks was adopted by other researchers, leading to the development of various nonparametric tests commonly used today. Representative examples include the Mann-Whitney U test [@Mann-Whitney-U] and the Kruskal–Wallis test [@Kruskal-Wallis] for independent samples, and the Wilcoxon sign-rank test [@Wilcoxon] and the Friedman test [@Friedman] for paired samples and repeated measures. 

### Rank transformations
 The scope of nonparametric tests is limited, as they only support simple experimental designs with a single independent variable. Rank transformations aim to address this limitation by bridging the gap between nonparametric statistics and ANOVA. 

**The rank transform.** @Conover:2012 provides a comprehensive introduction to the simple rank transform, which consists of sorting the raw observations and replacing them by their ranks. In case of ties, tied observations are assigned *fractional ranks* equal to their average order position in the ascending sequence of values. For example, the two $0.3$ instances of the $Y$ responses in @fig-ART-explained (a), which are the lowest values in the dataset, receive a rank of $1.5$ (see $rank(Y)$), while the next value (a $0.4$) in the sequence receives a rank of $3$. 

@conover:1981 showed that for one-factor designs, using ANOVAs on these ranks produces tests that are asymptotically equivalent or good replacements of traditional nonparametric tests (see [Section 3](#interpretation)). However, a series of studies in the 80s raised caution flags on the use of the method, showing that it may confound main and interaction effects in two-factor and three-factor experimental designs. For an extensive review of these studies, we refer readers to @Sawilowsky:1990.

**The aligned rank transform.** In response to these negative results, many researchers turned to aligned (or adjusted) rank transformations. @Sawilowsky:1990 discusses several variations of aligned rank-based transformations (ART) and tests, while @higgins:1990 describe the specific ART method that we evaluate in this paper for two-way designs. @wobbrock:2011 generalize it to more than two factors, and a decade later, @elkin:2021 show how to apply it to multifactor contrast tests. @fig-ART-explained explains the general method for a design with two factors, $A$ and $B$.

![Example showing the use of the rank, ART, and INT transformation methods (a). Construction of ART for a two-factor design (b,c)](images/art-explained.svg){#fig-ART-explained width=80%}
         
The key intuition behind the transform is that responses are ranked after they are *aligned*, such that effects of interest are separated from other effects. This implies that for each effect, either main or interaction, a separate ranking is produced. This is clearly illustrated in the example dataset shown in @fig-ART-explained (a), where each aligned ranking ($ART_A$, $ART_B$, and $ART_{AB}$) is for testing a different effect ($A$, $B$, and $A \times B$, respectively).

Even in this very small dataset ($n = 2$), the three ART rankings are distinct from one another and also differ significantly from the ranking produced by a simple rank transformation. Interestingly, identical responses (e.g., the two values of $0.3$) can be assigned very different ranks, while responses that differ substantially (e.g., $0.3$ and $3.0$) may receive the same rank. More surprisingly, larger values can receive lower ranks --- revealing that ART is a non-monotonic transformation. For instance, for subject $s_1$ under condition $b_1$, the responses are $0.4$ and $0.8$ for $a_1$ and $a_2$, yet their respective $ART_A$ ranks are $7.5$ and $3.0$. In this case, ART significantly distorts the actual difference between the two groups, $a_1$ and $a_2$.

As we will show later, this behavior can lead to unstable results and misleading conclusions, and it represents a central flaw of the method. For example, running a repeated-measures ANOVA on these ART ranks yields a *p*-value of $.044$ for the effect of $A$. In contrast, using a repeated-measures ANOVA on the ranks of simple rank transformation produces a *p*-value of $.46$, while applying a log-transformation --- more appropriate for this type of data --- yields a *p*-value of $.85$.

@fig-ART-explained (b-c) details the calculation of the transformation, where we highlight the following terms: (i) residuals (in yellow) that represent the unexplained error (due to individual differences in our example); (ii) main effects (in green and pink) estimated from the observed means of the individual levels of the two factors; and (iii) interaction effect estimates (in blue). Observe that the estimates of the two main effects are subtracted from the interaction term. The objective of this approach is to eliminate the influence of main effects when estimating interaction effects. 

This is not the only alignment technique discussed in the literature. @Sawilowsky:1990 suggests that, at least for balanced designs, interactions could also be removed when aligning main effects, in the same way main effects are removed when aligning interactions. This approach is also taken by @Leys:2010, who derived a common ranking for both main effects after subtracting the interaction term. We do not evaluate these alternative alignment methods in this paper, as they are, to the best of our knowledge, not commonly used in practice. 

**The inverse normal transform.** 
A third transformation method we evaluate is the rank-based inverse normal transformation (INT). INT has been in use for over 70 years [@VanDerWaerden:1952] and exists in several variations [@Beasley:2009;@Solomon2009]. Its general formulation is as follows: 

$$ 
INT(Y) = \Phi^{-1}(\frac{rank(Y) - c}{N - 2c + 1})
$${#eq-int}

where $N$ is the total number of observations and $\Phi^{-1}$ is the standard normal quantile function, which transforms a uniform distribution of ranks into a normal distribution. Different authors have used a different parameter $c$. In our experiments, we use the *Rankit* formulation [@Bliss:1956], where $c = 0.5$, since past simulation studies [@Solomon2009] have shown that it is more accurate than alternative formulations. However, as @Beasley:2009 report, the choice of $c$ is of minor importance. For our experiments, we implement the INT method in R as follows: 

```{r}
INT <- function(x){
	qnorm((rank(x) - 0.5)/length(x))
}
```

@fig-ART-explained (a) shows how this function transforms the responses for our example dataset. 

**Other non-parametric rank-based methods.** Several other rank-based statistical tests handle interactions, with the ANOVA-type statistic (ATS) [@Brunner_ATS:2001] being the most representative one. @Kaptein:2010 introduced this method to the HCI community, advocating its use for analyzing Likert-type data as a viable alternative to parametric ANOVA. In addition to ATS, Lüpsen [-@luepsen:2017; -@luepsen:2018; -@luepsen:2023] investigated several other multifactorial nonparametric methods. In particular, the author evaluated the hybrid ART+INT technique proposed by @Mansouri:1995, which applies INT on the ranks of ART. He also tested multifactorial generalizations of the van der Waerden test [@VanDerWaerden:1952] and the Kruskal-Wallis and Friedman tests [@Kruskal-Wallis;@Friedman]. The former is based on INT, but instead of using F-tests on the transformed values as part of ANOVA, it computes $\chi^2$ ratios over sums of squares. These two methods are not widely available, but implementations in R can be downloaded from Lüpsen's website [@luepsen_R]. 

### Experimental evaluations
Previous studies have evaluated ART and related procedures using various Monte Carlo simulations, often producing conflicting results and conclusions.

**Results in support of ART**. A number of experiments conducted during the 80s and 90s suggested that ART is robust for testing interaction effects. Noteworthy instances include studies, such as those by @Salter:1993, which compared the method to parametric ANOVA. The authors found that ART remains robust even in the presence of outliers or specific non-normal distributions, such as the logistic, exponential, and double exponential distributions. Their findings indicated only a marginal increase in error rates (ranging from 6.0% to 6.3% instead of the expected 5%) when applied to the exponential distribution. Furthermore, ART demonstrated superior statistical power compared to parametric ANOVA. @Mansouri:1995 evaluated ART under a different set of non-normal distributions (normal, uniform, log-normal, exponential, double exponential, and Cauchy) in the presence of increasing main effects. Except for the Cauchy distribution, ART maintained Type I error rates close to nominal levels across all scenarios, irrespective of the magnitude of main effects. In contrast, the error rates of the rank transformation reached very high levels (up to $100\%$) as the magnitude of main effects increased, even under the normal distribution. ART only failed under the Cauchy distribution, which is well-known to be pathological. 

More recently, @elkin:2021 compared ART to parametric t-tests for testing multifactor contrasts under six distributions: normal, log-normal, exponential, double exponential, Cauchy, and Student's t-distribution ($\nu=3$). Their results confirmed that ART keeps Type I error rates close to nominal levels across all distributions, except for the Cauchy distribution. In addition, they found that ART exhibits a higher power than the t-test. 

While most evaluation studies have focused on continuous distributions, @Payton:2006 have also studied how various transformations (rank, ART, log-transform, and squared-root transform) perform under the Poisson distribution, focusing again on interaction effects when main effects were present. The authors found that ART and parametric ANOVA (no transformation) performed best, keeping Type I error rates close to nominal levels. All other transformations inflated error rates.

**Warnings**. While the above results indicate that ART is a robust method, other studies have identified some serious issues. The second author of this paper has observed that, in certain cases, ART seems to detect spurious effects that alternative methods fail to identify [@casiez:2022]. Such informal observations, conducted with both simulated and real datasets, motivated us to delve deeper into the existing literature.

@Carletti:2005 report that *"aligned rank transform methods are more affected by unequal variances than analysis of variance especially when sample sizes are large."* Years later, @luepsen:2018 conducted a series of Monte Carlo experiments, comparing a range of rank-based transformations, including the rank transformation, ART, INT, a combination of ART and INT (ART+INT), and ATS. His experiments focused on a $2 \times 4$ balanced between-subjects design and a $4 \times 5$ severely unbalanced design and tested normal, uniform, discrete uniform (integer responses from 1 to 5), log-normal, and exponential distributions, with equal or unequal variances. Furthermore, they tested both interaction and main effects when the magnitude of other effects increased. The results revealed that ART inflates error rates beyond acceptable levels in several configurations: right-skewed distributions (log-normal and exponential), discrete responses, unequal variances, and unbalanced designs. @luepsen:2018 also found that using INT in combination with ART (ART+INT) is preferable to the pure ART technique. However, as the method still severely inflated error rates in many settings, @luepsen:2018 concluded that both ART and ART+INT are *"not recommendable."* 

Another notable finding by @luepsen:2018 was that the simple rank transformation *"appeared not as bad as it is often described"* [@luepsen:2018], outperforming ART in many scenarios, such as discrete and skewed distributions, or distributions with unequal variances. These results are in full contradiction with the findings of @Mansouri:1995.

The same author conducted an additional series of experiments [@luepsen:2017], focusing on two discrete distributions (uniform and exponential) with a varying number of discrete levels: 2, 4, and 7 levels with integer values for the uniform distribution, and 5, 10, and 18 levels with integer values for the exponential distribution. Again, the Type I error rates of both ART and ART+INT reached very high levels, but error rates were especially pronounced when the number of discrete levels became small and the sample size increased. Given these results, the author's conclusion was the following: 

> *"the ART as well as the ART+INT cannot be applied to Likert and similar metric or ordinal scaled variables, e.g. frequencies like the number of children in a family or the number of goals, or ordinal scales with ranges from 1 to 5"* [@luepsen:2017]. 

**Results on other rank-based methods.** We are also interested in understanding how ART compares with INT, which is frequently used in some research domains, such as genetics research [@Beasley:2009]. @Beasley:2009 conducted an extensive evaluation of the method and reached the conclusion that *"INTs do not necessarily maintain proper control over Type 1 error rates relative to the use of untransformed data unless they are coupled with permutation testing."* @luepsen:2018 included INT in his evaluation and found that in most cases, it maintained better control of Type I error rates compared to ART and the pure rank transformation, while also presenting a higher statistical power. However, he also identified several cases where INT failed to sufficiently control for Type I errors, such as design configurations with unequal variances in unbalanced designs or skewed distributions, and when testing interactions in the presence of non-null main effects.

In addition to INT, @luepsen:2018 evaluated the ATS method but found it to suffer from low power while presenting similar challenges as the rank transformation with regard to Type I error rates. Amongst all evaluated methods, the author identified the generalized van der Waerden test as the method that provided the best overall control of Type I error rates. More recently, @luepsen:2023 conducted a new series of experiments testing rank-based nonparametric methods on split-plot designs with two factors. While the author reported on various tradeoffs of the methods, he concluded that overall, the generalized van der Waerden test and the generalized Kruskal-Wallis and Friedman tests were the best performing methods.

### The use of ART in experimental research {#ART-use}
To get a sense of how frequently ART is used in experimental research, we examined the citations of ARTool [@wobbrock:2011] indexed by Google Scholar. As shown in @fig-ARTool-citations), the rate of citations to the original CHI 2011 paper introducing the method to the HCI community is steadily increasing, with over 400 citations in 2023 alone. 

![Citations of the CHI 2011 paper on ARTool [@wobbrock:2011] as shown in Google Scholar on 28 April 2024. We analyzed the 439 citing bibliographic entries of 2023 in more detail. *Note: Citations have continued to increase throughout the 2024–2025 period.*](images/ARTool-citations-28-april-2024.png){width=80% #fig-ARTool-citations}

@fig-ART-citations-venues presents the most frequently citing venues for 2023. We observe that the HCI, Augmented Reality (AR), and Virtual Reality (VR) venues dominate these citations. However, we found that ARTool is used in other scientific disciplines. For example, among the papers published in 2023, we counted nine Nature Scientific Reports and a total of 25 articles appearing in journals with the words "neuro" or "brain" in their title, including the Journal of Neuropsychology (three citations), the Journal of Neuroscience (two citations), the Journal of Cognitive Neuroscience (two citations), Neuropsychologia (two citations), Nature Neuroscience, Neuropharmacology, Brain, and NeuroImage. 

::: {#fig-ART-citations-venues}
```{r, echo=FALSE, message=FALSE, fig.height=4.5, fig.width = 8, warning=FALSE}
library(ggplot2)
library(bib2df)
library(stringr)

df <- bib2df("2023-papers/citations-ART-2024-no-theses.bib")

df$venue <- tools::toTitleCase(ifelse(!is.na(df$JOURNAL), df$JOURNAL, df$BOOKTITLE))
 venues <- df %>%
  filter(!is.na(venue)) %>%
  group_by(venue) %>%
  summarize(n = n()) %>%
  arrange(desc(n))

venues <- venues %>% slice(1:17)
venues$venue <- factor(venues$venue, levels = venues$venue[order(venues$n)])

plot <- ggplot(venues, aes(x = venue, y = n)) +
  geom_col(fill = "gray70") +
  geom_text(
    aes(label = n), 
    ## make labels left-aligned
    hjust = 1, nudge_y = -.4, 
  ) + coord_flip()  +
  theme_void() + theme(axis.title = element_blank()) + 
  theme(axis.text.y = element_text(size = 10, hjust = 1, family = "Arial"),
        plot.margin = margin(rep(15, 4)))

plot
```
Publication venues with the highest number of citations to ARTool [@wobbrock:2011] in 2023. Note that among the articles published in the IEEE Transactions on Visualization and Computer Graphics, eight articles appeared at the IEEE International Symposium on Mixed and Augmented Reality (IEEE ISMAR'23), and three articles appeared at the IEEE Conference on Virtual Reality and 3D User Interfaces (IEEE VR'23). So the total number of citing articles appearing at these two venues is 19 for IEEE ISMAR'23 and 10 for IEEE VR'23. 
:::

To gain insights into the prevalent experimental designs using ART, we examined a subset of citing papers comprising the 39 most recent English publications as of November 2023. Among these, 25 report using a within-participants design, three papers report using a between-participants design, while 11 papers report using a mixed design that involved both between- and within-participants factors. The number of factors ranges from one to five, with two factors representing approximately 64% of the experimental designs. Participant counts in these studies vary between 12 and 468, with a median of 24 participants. Within-cell sample sizes (n) range from 8 to 48, with a median of 20. 

Furthermore, we explored the types of data analyzed using ART. Among the 39 papers, 21 use ART for analyzing ordinal data, often in conjunction with other data types. Ordinal data include responses to Likert scales or other scales of subjective assessment, such as the NASA Task Load Index (NASA TXL) [@hart1988development]. Furthermore, several authors apply ART to individual ordinal items, including Likert items with five levels (two papers), seven levels (seven papers), and 11 levels (three papers). Other types of data for which the method is used include task-completion or response times, counts, and measures of accuracy, such as target hit rates or recall scores. A common rationale for employing ART for such measures is the detection of departures from normality assumptions, often identified through tests like the Shapiro-Wilk test. Interestingly, several authors use ART only for ratio data, opting for nonparametric tests such as the Friedman test when analyzing ordinal data. 

Out of the 39 papers examined, 38 identify at least one statistically significant main effect using ART. Additionally, 30 papers conduct tests for interactions, with 24 of them reporting at least one statistically significant interaction effect. Only five papers have publicly available data. We revisit the results of three of these papers in [Section 7](#casestudies).

<!----
with subgroups ranging from 8 to 48 (median = 20.0). For dependent variables, 51.3% of the studies used ratio variables and the remaining ordinal variables.  94.9% of the studies found at least one significant main effect in the results, using the ART. 80.0% of the studies studying the interaction between factors using the ART found at least one significant interaction. Only 12.8% of the papers made the data of their studies publicly available. --->

### Positioning
We observe that ART is frequently used for the analysis of experimental results. Interestingly, the cautions raised by Lüpsen [-@luepsen:2017; -@luepsen:2018] have been widely overlooked, and ART is commonly applied to datasets, including Likert data with five or seven levels, where the method has been identified as particularly problematic. Given the contradictory findings in the existing literature, researchers grapple with significant dilemmas regarding which past recommendations to rely on.

Our goal is to verify Lüpsen's findings by employing an alternative set of experimental configurations and a distinctly different methodology. In particular, we adopt a latent variable modeling approach that establishes a unified framework for data generation across all distributions. This approach allows us to identify interpretation issues regarding the definition of the null hypothesis, especially for interaction effects, and better explain when and why each method fails. Moreover, it facilitates the assessment of the methods through more suitable generation procedures for ordinal data, as suggested by @Liddell:2018.
Our simulation strategy is similar to that of @elkin:2021 but employs a simpler method for generating data from a latent parameter space. In addition, we evaluate critical scenarios that @elkin:2021 did not consider, particularly the influence of no-null effects and discrete data. 

With a focus on clarity, we chose to exclusively examine the three rank-based transformations presented earlier: the pure rank transformation (RNK), ART, and INT. While we do not elaborate on the performance of ATS in the main paper, additional experimental results are available in the [appendix](appendix.html#ATS). These findings indicate that its performance is comparable to the rank transformation but seems to be inferior to the simpler and more versatile INT. The [appendix](appendix.html#generalized) features additional results regarding the performance of the generalized van der Waerden test, as well as the generalized Kruskal-Wallis and Friedman tests. Our findings show that, at least in balanced designs, these methods suffer from low power issues in certain situations without demonstrating any clear benefits compared to INT.

Finally, we chose to limit our investigation to balanced experimental designs. The rationale behind this decision is that we have not encountered any prior claims about ART's suitability for unbalanced data, and the ARTool [@artool] issues a warning in such situations. However, the [appendix](appendix.html#missing) presents additional results on experimental designs with missing data, which confirm that in such situations, ART's accuracy may deteriorate further.