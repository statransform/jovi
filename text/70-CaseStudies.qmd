## Case studies {#casestudies}
In this section, we examine some specific types of data through concrete examples. We focus on recent work (published in 2023) that has used ART and made data publicly available. We identify problems and evaluate possible risks. We also present alternative methods for conducting the analysis and compare their outcomes.

### Binary responses

@Martin:2023 ran two experiments to investigate the psychological phenomenon of change blindness, that is, how humans fail to detect certain changes in a scene. We focus here on their first experiment, which evaluated how 22 participants succeeded in observing object manipulations in an immersive environment. The authors studied the influence of four different factors, namely the Type of manipulation (4 levels), its Distance from the observer (2 levels), the Complexity of the manipulated item (2 levels), and the field of view (not examined here). To analyze the effect of the first three factors, the authors used a $4 \times 2 \times 2$ repeated-measures ANOVA using ART. 

Their design has two particularities. First, the response variable is binary (Detected vs. Not Detected). Second, the design is unbalanced; each participant did not complete the same tasks, so their types and complexities did not appear with the same frequency among participants. The authors pointed to these issues to justify the use of ART: 

> *"Since we are dealing with **nonparametric, unbalanced data** and multiple factors, we apply the Aligned Rank Transform (ART) for nonparametric factorial ANOVA"* [@Martin:2023]. 

In their ART model, the authors treated the participant identifier and the task identifier as random effects. We could re-run their analysis to replicate the results presented in Table 1 [@Martin:2023]. However, we extended the analysis by fitting a linear mixed-effects model (LMER function) without any transformation (PAR). When responses are binary, RNK and INT do not alter the data, leading to results that coincide with those of PAR. 

Below, we present the *p*-values obtained from each method:

|  | ART | PAR |
|------|-----|-----|
| Type | $.92$ | $.016$ |
| Distance | $.031$ | $.12$ |
| Complexity | $.023$ | $.0027$ |
| Type $\times$ Distance | $.71$ | $.13$ |
| Type $\times$ Complexity | $.00077$ | $.0039$ |
| Distance $\times$ Complexity | $.0011$ | $.0029$ | 
| Type $\times$ Distance $\times$ Complexity | $.00055$ | $.00016$ |
: *p*-values keeping two significant digits - Type III hypothesis tests {.sm}

There are notable differences between the results obtained from the two methods, but it is important to note that the aforementioned *p*-values are outcomes of Type III hypothesis tests. While these tests are deemed more suitable for unbalanced data when interaction effects emerge, their use remains a subject of debate [@Smith:2022], and some experts argue that interpreting main effects in the presence of interactions may not be meaningful [@Hector:2010]. Thus, the presence of interactions in the above unbalanced design complexifies the detection and interpretation of main effects. In this specific case, the authors decided to create partial models with two factors each time to further evaluate contrasts, and interestingly, they now used t-tests instead of ART.   

We emphasize that the ARTool raises a warning for such unbalanced designs:

> *F values of ANOVAs on aligned responses not of interest are not all ~0. ART may not be appropriate.*

Our tests in the [appendix](appendix.html) show that ART's Type I error rates for main effects increase further in unbalanced designs with missing data.

**Monte Carlo simulation.** What if the experimental design were balanced, and such issues did not emerge? What risks would arise from using ART with such binary responses? To delve into this issue, we conduct a new Monte Carlo experiment.

Like @Martin:2023, we investigate a $4 \times 2 \times 2$ repeated-measures design and set the number of participants to $n=22$. However, we now test a perfectly balanced design. We transform the latent variable to a Bernoulli distribution with a success probability parameter $p=.46$ --- average success rate found by @Martin:2023 --- and then assess the Type I error rate of ART in the absence of any effect. We also assess the Type I error rate of regular ANOVA (LMER model) with no transformation (PAR). Our results over 5000 iterations are as follows:

|  | $X_1$ | $X_2$ | $X_3$ | $X_1 \times X_2$ | $X_1 \times X_3$ | $X_2 \times X_3$ | $X_1 \times X_2 \times X_3$ |
|------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
| PAR/LMER | $4.4$ | $4.5$ | $4.6$ | $5.5$ | $5.1$ | $5.2$ | $4.9$ |
| ART | $22.4$ | $19.9$ | $20.2$ | $22.6$ | $21.8$ | $19.8$ | $21.1$ |
: Type I error rates (%) for $\alpha = .05$ (nominal error rate $=5\%$) and $p=.46$ {.sm}

|  | $X_1$ | $X_2$ | $X_3$ | $X_1 \times X_2$ | $X_1 \times X_3$ | $X_2 \times X_3$ | $X_1 \times X_2 \times X_3$ |
|------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
| PAR/LMER | $0.7$ | $1.1$ | $0.9$ | $1.1$ | $1.0$ | $1.1$ | $1.0$ |
| ART | $10.0$ | $8.8$ | $9.7$ | $10.6$ | $9.7$ | $9.6$ | $9.9$ |
: Type I error rates (%) for $\alpha = .01$ (nominal error rate $=1\%$) and $p=.46$ {.sm}

We observe that ART exhibits significant challenges with such binary data, as its error rates escalate to very high levels for all main and interaction effects. In contrast, PAR (LMER) consistently maintains error rates close to nominal levels. We extend our simulation to Bernoulli distributions with a low success (or error) probability parameter $p=.06$. The results are now as follows: 

|  | $X_1$ | $X_2$ | $X_3$ | $X_1 \times X_2$ | $X_1 \times X_3$ | $X_2 \times X_3$ | $X_1 \times X_2 \times X_3$ |
|------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
| PAR/LMER | $4.9$ | $4.8$ | $6.0$ | $4.4$ | $4.0$ | $4.6$ | $4.6$ |
| ART | $78.1$ | $68.6$ | $68.7$ | $71.9$ | $71.3$ | $68.8$ | $70.5$ |
: Type I error rates (%) for $\alpha = .05$ (nominal error rate $=5\%$) and $p=.06$ {.sm}

|  | $X_1$ | $X_2$ | $X_3$ | $X_1 \times X_2$ | $X_1 \times X_3$ | $X_2 \times X_3$ | $X_1 \times X_2 \times X_3$ |
|------:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
| PAR/LMER | $1.0$ | $1.0$ | $1.2$ | $0.8$ | $0.7$ | $1.1$ | $0.9$ |
| ART | $68.6$ | $60.6$ | $60.2$ | $61.6$ | $60.1$ | $60.6$ | $59.9$ |
: Type I error rates (%) for $\alpha = .01$ (nominal error rate $=1\%$) and $p=.06$ {.sm}

Clearly, ART is completely inappropriate when responses are binary. In contrast, parametric ANOVA demonstrates an excellent behavior even when the success (or error) rate is as low as $6\%$. 

A more adapted approach for this type of data would be to use a generalized linear model (GLMER) with a *binomial link function*, which essentially performs a logistic regression. Such models are in line with the latent variable approach, where the link function establishes a connection between a normally distributed latent psychological variable (e.g., the human ability to detect changes in a virtual environment) and the observed variable (e.g., successes or failures in sequential change detection tests). Consequently, we expect them to exhibit stronger predictive power than regular linear models and support a more appropriate interpretation of interaction effects. However, inference with such models requires additional steps, such as comparing alternative models using various criteria [@Bolker2009glm], so we do not include them in our evaluation here.

### Likert items 

@Rosso:2023 conducted a body-swap experiment, where pairs participants ("dyads") performed a joint-finger tapping task under four different conditions, structured under two different factors:

- *Coupling*. Participants saw either their own hand (*Coupled*) or their partner's hand (*Uncoupled*).

- *Perspective*. Participants saw the hand from a first person (*1P*) perspective or from a second person perspective (*2P*). 

Overall, the experiment was structured as a $2 \times 2$ within-participants design with 38 participants (19 dyads). The authors investigated numerous measures. Here, we only revisit their analysis of the sense of ownership of the visually perceived hand, for which they used ART (Page 10). The variable was measured through a self-reported scale with five levels (1 to 5). The authors report:

> *Aligned rank transform (ART) ANOVA revealed significant main effects of Coupling (Df residual = 147, F = 104.353, p < 0.001) and Perspective (Df residual = 147, F = 8.983, p < 0.01) on the self-reported ownership ratings. The former indicates that participants were capable of telling apart their own hand from the partnerâ€™s regardless of the visual perspective, whilst the latter indicates that perceiving a hand in 1st person generally resulted in a stronger sense of ownership. Crucially, the interaction effect between Coupling and Perspective (Df residual = 147, F = 5.232, p < 0.05) revealed that the increase in ownership relative to the 2nd person perspective was significantly stronger when participants were coupled.* [@Rosso:2023]

Thus, the authors found supportive statistical evidence for both main effects and the interaction of the two factors. We replicated their analysis and found that the author did not conduct a repeated-measures ANOVA, i.e., they did not treat ratings from the same participant as independent. We re-analyzed the data with a mixed-effects *lmer* model, treating the participant identifier as a random effect nested under the identifier of participant pairs (dyads). Conclusions do not change since our analysis is more powerful, so $p$-values are now even smaller for all three effects. However, we also conducted the analysis using the three other methods (PAR, RNK, INT), and unfortunately, conclusions are very different:

|  | ART | PAR | RNK | INT |
|------|-----|-----|-----|-----|
| Coupling | $3.2 \times 10^{-19}$ | $4.9 \times 10^{-18}$ | $9.5 \times 10^{-20}$ | $5.4 \times 10^{-19}$ |
| Perspective | $.0016$ | $.20$ | $.25$ | $.29$ |
| Coupling $\times$ Perspective | $.015$ | $.78$ | $.90$  | $.95$ |
: *p*-values keeping two significant digits {.sm}

All four methods agree that there is strong evidence about the effect of Coupling. Nevertheless, the results of PAR, RNK, and INT for the effects of Perspective and Coupling $\times$ Perspective do not support the authors' conclusions. The discrepancy between the $p$-values returned by these methods and the $p$-values of ART is striking. 

One may notice that a single entry (out of 152 entries) in the above dataset is missing, so the design is slightly unbalanced, and the ARTool again outputs a warning. Could this imbalance explain the above differences? The answer is negative. If we complete the missing row with a neutral value (e.g., a 3 in the 5-level ordinal scale) to dismiss the warning, the resulting *p*-values will still be very similar to the ones reported above.  

**Ordered probit models.** We conducted complementary analyses with ordered probit models, where we used two different methods: (1) ordinal regression as implemented in the *ordinal* R package [@Christensen2023ordinal]; and (2) a Bayesian statistics framework with the *brms* R package [@Burkner:2019]. 

For the first (frequentist) analysis, we use the following R code:

```{r, eval=FALSE}
library(ordinal)
# We make sure that the response variable is treated as ordinal
ownership_data$ownership <- factor(ownership_data$ownership, ordered = TRUE) 

fit_frequentist <- clmm(
  ownership ~ Coupling + Perspective + Coupling:Perspective + (1|Dyad/Participant),
  link = "probit", 
  threshold = "flexible",
  data = ownership_data
)
```

We can build a simpler regression model by setting ```threshold = "equidistant"``` and compare the two models by conducting a likelihood-ratio test. For this specific example, the flexible thresholds do not improve the model's predictive power, so the simpler model is more promising. However, both models lead to almost identical parameter estimates. 

For the Bayesian formulation, we use the following code in R:

```{r, eval=FALSE}
library(brms)
fit_ownership <- brm(
  formula = ownership ~ Coupling + Perspective + Coupling:Perspective 
    + (1|Dyad/Participant),
  data = ownership_data,
  family = cumulative("probit")
)
```

Notice that we do not use informative priors in the above model, although this is possible. For an extensive discussion about why using a Bayesian framework for this type of analysis, we refer interested readers to @Liddell:2018. @Burkner:2019 provide an excellent introductory tutorial to this approach. Its main shortcoming is the substantial computational resources it demands, whereas fitting a model with the frequentist approach is extremely fast. 

Below, we present parameter estimates from the two methods, where brackets represent either $95\%$ confidence intervals (frequentist method), or $95\%$ credible intervals (Bayesian method):

| | Frequentist [@Christensen2023ordinal] | Bayesian [@Burkner:2019] |
|-----|-----|------|
| Coupling (Coupled $-$ Uncoupled) | $-1.85$ $[-2.46, -1.24]$ | $-1.95$ $[-2.58, -1.35]$  |
| Perspective (1P $-$ 2P) |  $\quad 0.29$ $[-0.37, 0.94]$  | $\quad 0.28$ $[-0.39, 0.95]$ |
| Coupling $\times$ Perspective | $-0.11$ $[-0.93, 0.70]$| $-0.09$ $[-0.89, 0.75]$ |
: Effect estimates and their $95\%$ confidence or credible intervals. They are expressed as standard deviations of the latent variable {.sm}


Interpreting these results requires special attention, as the above estimates do not refer to the observed ordinal scale of measurements. All effects are expressed in standard deviation units over the latent variable, so they are analogous to Cohen's $d$ standardized effect sizes. The above results suggest that participants' sense of ownership was $1.85$ (or $1.95$) standard deviations lower in the Coupled condition, where standard deviations refer to the continuous latent scale of sense of ownership. 

The whole $95\%$ CI for both methods is far below zero, which means that there is overwhelming evidence that this effect is strong. In contrast, we observe that the intervals for Perspective and the interaction term extend from negative to positive values. Thus, there is no sufficient statistical evidence for these effects. If we subsequently conduct a likelihood-ratio test with alternative models, the simpler model with ```formula = ownership ~ Coupling + (1|Dyad/Participant)``` will be the winning one.

These results are consistent with the results of our *lmer* models using PAR, RNK, and INT. In conclusion, using ART to analyze these data is problematic. Here, the presence of a strong effect on the first factor seems to make ART sensitive in detecting other non-existent effects (or perhaps in amplifying tiny effects). 

### Likert scales

Other authors have used ART to analyze Likert scales that group several items together. For example, @Karolus:2023 investigate different methods (referred to as "gamification types") for communicating feedback on users' task proficiency, such as during a writing task. The authors used a $3 \times 2$ between-participants design to structure the study, testing the following two factors:

- *Gamification type*. Each participant was presented with one of the following elements providing feedback: (i) a *progress bar* (ii) an *Emoji*, or (iii) *none*. 

- *Feedback type*. Feedback was either *continuous* or *revision*-based (provided at the end of the task to help participants revise). 

The authors collected responses from 147 participants through the Amazon Mechanical Turk Service. They analyzed a range of measures, but here we focus on their analysis of participants' responses to the Situational Motivation Scale (SIMS) [@Blanchard_SIMS:2000]. The scale consists of four subscales (intrinsic motivation, identified regulation, external regulation, and amotivation), where each contains four 7-level Likert items. For each subscale, the authors conducted an ANOVA using ART on the average score. Below, we present the results of the same analysis with all four methods for intrinsic motivation and identified regulation:

|  | ART | PAR | RNK | INT |
|------|-----|-----|-----|-----|
| Gamification | $.0057$ $(0.07)$| $.010$ $(0.06)$| $.0058$ $(0.07)$| $.0062$ $(0.07)$|
| Feedback | $.77$ | $.59$ | $.56$ | $.55$ |
| Gamification $\times$ Feedback | $.94$ | $.69$ | $.94$  | $.86$ |
: Intrinsic motivation: *p*-values keeping two significant digits (partial $\eta^2$ in parentheses when $p < .05$) {.sm}

|  | ART | PAR | RNK | INT |
|------|-----|-----|-----|-----|
| Gamification | $.019$ $(0.05)$ | $.011$ $(0.06)$ | $.013$ $(0.06)$ | $.0085$ $(0.07)$|
| Feedback | $.55$ | $.74$ | $.42$ | $.55$ |
| Gamification $\times$ Feedback | $.99$ | $.86$ | $.98$  | $.93$ |
: Identified regulation: *p*-values keeping two significant digits (partial $\eta^2$ in parentheses when $p < .05$) {.sm}

Overall, differences between the results of the four methods are reasonably small and support the authors' conclusions. We omit results for external regulation and amotivation for which all *p*-values are greater than $.05$ --- again, results are consistent among the four methods. 

In many situations, the above methods will behave correctly and produce similar results. However, it is difficult to know in advance when problems will arise. In a different experiment, @Siestrup:2023 investigated how different types of modifications in video sequences describing a story affect people's episodic memory. The experiment included a rating task, asking participants to rate how much the storyline of modified episodes deviated from an original version (from $1 = 0\%$ different to $6 = 100\%$ different). The authors used ART to analyze aggregated scores from multiple ratings per condition. Below, we present the results of our re-analysis with the four different methods:

|  | ART | PAR | RNK | INT |
|------|-----|-----|-----|-----|
| Version | $4.5 \times 10^{-20}$ | $2.7 \times 10^{-30}$ | $4.7 \times 10^{-20}$ | $2.0 \times 10^{-17}$ |
| Modification | $.034$ | $.11$ | $.23$ | $.40$ |
| Version $\times$ Modification | $.19$ | $.17$ | $.18$  | $.058$ |
: *p*-values keeping two significant digits {.sm}

We see now that results from different methods can lead to different conclusions. In particular, the authors' statement that *"modified videos that had already been presented during the fMRI session received lower story-change ratings than those that had been presented in the original version before"* [@Siestrup:2023], based on the observed effect of the second factor (Modification), is only supported by their analysis with ART. Effect size estimates for this factor also vary among methods, although their wide confidence intervals indicate that those estimates are highly uncertain: 

|  | ART | PAR | RNK | INT |
|------|-----|-----|-----|-----|
| partial $\eta^2$| $0.12$ $[.01, 1.0]$ | $0.07$ $[.00, 1.0]$| $0.04$ $[.00, 1.0]$| $0.02$ $[.00, 1.0]$|
: effect size estimates for Modification and their $95\%$ confidence intervals {.sm}

**Ordered probit models.** Alternatively, we can use ordered probit models [@Burkner:2019;@Christensen2023ordinal], as we did for the analysis of individual Likert items. To this end, we do not average the individual Likert items of the scale but treat instead items and participants as a random effects. For example, to analyze participants' responses for intrinsic motivation [@Karolus:2023], we can use the following formula: 

```formula = intrinsic_motivation ~ 1 + Gamification:Feedback + (1|Item) + (1|Participant)```

Interested readers can refer to our supplementary material for additional details.
