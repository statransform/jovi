---
title: "The illusory promise of the Aligned Rank Transform"
subtitle: "A systematic study of rank transformations"
author: 
  - name: Theophanis Tsandilas
    orcid: 0000-0002-0158-228X
    email: theophanis.tsandilas@inria.fr
    affiliations:
      - name: Université Paris-Saclay, CNRS, Inria, LISN
        country: France
  - name: Géry Casiez
    orcid: 0000-0003-1905-815X
    email: gery.casiezuniv-lille.fr
    affiliations:
      - name: Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 CRIStAL
        country: France
bibliography: bibliography.bib
csl: canadian-journal-of-philosophy.csl

tbl-cap-location: top
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Useful libraries
library(crosstalk)
library(kableExtra)
library(gridExtra)
library(lmerTest)
library(tidyverse)
library(plotly)
```

```{=html}
<style>
.math.inline .MathJax  {
  font-size: 105% !important;
}
</style>
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyverse)

source("utils-data-reading.R")
source("utils-plotlying.R")
source("utils-plotlying-single.R")
```

```{=html}
<style>
.math.inline .MathJax  {
  font-size: 105% !important;
}
</style>
```

We present complementary results and new experiments that investigate additional scenarios. We also compare INT and RNK with other nonparametric methods. Unless explicitly mentioned in each section, we follow the experimental methodology presented in the main article. At the end of each section, we summarize our conclusions.

## Nonparametric tests in single-factor designs {#nonparametric-tests}
We compare PAR, RNK, and INT to classical nonparametric tests for single-factor designs with both within- and between-subjects structures, where the factor has two, three, or four levels. Depending on the design, different nonparametric tests are used. For within-subjects designs, we apply the Wilcoxon signed-rank test when the factor has two levels (2 *within*), and the Friedman test when the factor has three (3 *within*) or four (4 *within*) levels. For between-subjects designs (2 *between*, 3 *between*, and 4 *between*), we use the Kruskal–Wallis test.

**Type I error rates and power**. @fig-nonparametric-power compares the proportion of positive test results as a function of effect magnitude, using the label *NON* to denote the corresponding nonparametric test. When the true effect is null, this proportion represents the Type I error rate; under non-null effects, it represents statistical power. 

For null effects, all nonparametric tests exhibit appropriate Type I error control across all distributions. Under non-null effects, power differences are generally small for between-subjects designs (Kruskal–Wallis test) and for within-subjects designs with two levels (Wilcoxon signed-rank test). However, we find substantial differences for within-subjects designs with three or four levels, where the Friedman test is used. These findings corroborate Conover’s [-@Conover:2012] observation that rank-transformed ANOVA can outperform the Friedman test under certain conditions. Overall, INT emerges as the most powerful method.

```{r, echo=FALSE, warning=FALSE, message=FALSE}
alpha = 0.05
distributions = c("norm", "lnorm", "exp", "poisson", "binom", "likert")
dnames = c("Normal", "Log-normal", "Exponential", "Poisson", "Binomial", "Ordinal (5 levels)")
methods = c("PAR", "RNK", "INT", "NON")
palette = c("#888888", "#E69F00", "#009E73", "#FF70AB")

prefix <- "Power_single_factor"
df <- read_single(prefix, alpha, distributions, methods = methods, POWER = TRUE)
df <- df %>% arrange(design,family,effect,rate)  %>% group_by(design,family,effect) %>% mutate(rank = rank(rate))

df <- as.data.frame(df) %>% reshape_by_design(dnames, effectvars = c("effect"))
```

::: {#fig-nonparametric-power}
<div id="plot-power-single-1">
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
plotly_error_by_design_single(df, xlab = "magnitude of effect", ytitle = "Positives (%)", var = "rate", xvar = "effect", max = 103, cbPalette = palette)
```
</div>

<div id="plot-power-single-2">
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
plotly_power_by_design_single(df, xlab = "magnitude of effect", var = "rank", xvar = "effect", ytitle = "Positives - ranking", max = 4.3, cbPalette = palette)
```
</div> <style> .hidden { display: none; } </style> <script> document.addEventListener("DOMContentLoaded", function() { document.getElementById("plot-power-single-2").classList.add("hidden"); }); </script>

<button id="btn_single" style="background-color: #f0f0f0; border: 1px solid #ccc; color: #333; font-size: 0.9em;
    padding: 4px 10px; border-radius: 6px; cursor: pointer; float: right;"
  onclick="const plot = document.getElementById('plot-power-single-1');
  plot.classList.toggle('hidden');
  document.getElementById('plot-power-single-2').classList.toggle('hidden');
  btn_single.innerText = plot.classList.contains('hidden') ? 'show percent' : 'show ranking';
">
  show ranking
</button>

Ratio of positives ($\alpha = .05$) as a function of effect magnitude ($n=20$). For null effects, the ratio represents the Type I error rate. Otherwise, it corresponds to statistical power. 
:::

**Type I error rate under equal and unequal variances**. @fig-nonparametric-unequal-var reports positive rates under conditions of equal ($r_{sd} = 0$) and unequal variances ($r_{sd} > 0$). We focus on normally distributed data and ordinal scales with five and eleven levels. When variances are equal, the positive rate can be interpreted as the Type I error rate. Under unequal variances, interpretation requires caution because the underlying null hypotheses may differ across methods. 

For between-subjects designs, the Kruskal–Wallis test and RNK produce nearly identical results, as expected, since RNK is a close approximation of the Kruskal–Wallis test [@Conover:2012]. For within-subjects designs, the differences among methods are more pronounced, with RNK generally yielding the highest positive rates among nonparametric approaches. Across ordinal scales with flexible thresholds, all methods produce positive rates exceeding $5\%$, which is unsurprising given that unequal variances alter the interpretation of effects in these conditions.

::: {#fig-nonparametric-unequal-var}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
prefix <- "Type_I_single_factor"
distributions = c("norm", "likert_5", "likert_5_flex", "likert_7", "likert_7_flex")
dnames = c("Normal", "Equidistant (5 levels)", "Flexible (5 levels)", "Equidistant (7 levels)", "Flexible (7 levels)")

df <- read_single(prefix, alpha, distributions, methods = methods)
df <- reshape_by_design(df, dnames, effectvars = c("sd_ratio", "effect"))

plotly_error_by_design_single(df, xlab = "max ratio of standard deviations", ytitle = "Positives (%)", var = "rate", xvar = "sd_ratio", max = 14.2, cbPalette = palette)
```
Positives rates ($\alpha = .05$) as a function of the maximum ratio $r_{sd}$ of standard deviations between levels ($n = 20$). Depending on the null hypothesis of interest, these values may be interpreted as Type I error rates.
:::

### Conclusion
We find no substantial advantages in using classical nonparametric tests over RNK or INT. In particular, INT effectively replaces conventional nonparametric tests even in single-factor designs, while offering superior power and broader applicability.
