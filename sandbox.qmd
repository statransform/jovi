---
title: "The illusory promise of the Aligned Rank Transform"
subtitle: "A systematic study of rank transformations"
author: 
  - name: Theophanis Tsandilas
    orcid: 0000-0002-0158-228X
    email: theophanis.tsandilas@inria.fr
    affiliations:
      - name: Université Paris-Saclay, CNRS, Inria, LISN
        country: France
  - name: Géry Casiez
    orcid: 0000-0003-1905-815X
    email: gery.casiezuniv-lille.fr
    affiliations:
      - name: Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 CRIStAL
        country: France
bibliography: bibliography.bib
csl: canadian-journal-of-philosophy.csl

tbl-cap-location: top
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
# Useful libraries
library(crosstalk)
library(kableExtra)
library(gridExtra)
library(lmerTest)
library(tidyverse)
library(plotly)
```

```{=html}
<style>
.math.inline .MathJax  {
  font-size: 105% !important;
}
</style>
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(dplyr)
library(tidyverse)

source("utils-data-reading.R")
source("utils-plotlying.R")
```

```{=html}
<style>
.math.inline .MathJax  {
  font-size: 105% !important;
}
</style>
```

We present complementary results and new experiments that investigate additional scenarios. We also compare INT and RNK with other nonparametric methods. Unless explicitly mentioned in each section, we follow the experimental methodology presented in the main article. At the end of each section, we summarize our conclusions.

## Generalizations of nonparametric tests {#generalized}

Finally, we evaluate the generalizations of nonparametric tests recommended by Lüpsen [-@luepsen:2018; -@luepsen:2023] as implemented in his `np.anova` function [@luepsen_R]. Specifically, we examine the generalization of the van der Waerden test (VDW) and the generalization of the Kruskal-Wallis and Friedman tests (KWF). 

These implementations require random slopes to be included in the error term of the model. Concretely, we use ``Error(Subject/(X1*X2))`` for the two-factor within-participants design and ``Error(Subject/X2)`` for the mixed design. We use the same modeling approach for all other methods to ensure comparability.

**Type I error rates: Main effects**. @fig-vdWaerden-designs-main shows the Type I error rates for the main effect of $X_2$. While all methods perform well under the within-subjects and mixed designs, the error rates of VDW and KWF drop sharply as the effect of $X_1$ increases under the between-subjects design. As shown below, this behavior reflects a severe loss of power for these two methods in these conditions. We omit results for the other factor ($X_1$ as $a_2$ increases) as we observe very similar trends.

::: {#fig-vdWaerden-designs-main}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
prefix <- "Type_I_vdWaerden"
alpha = 0.05

distributions = c("norm", "lnorm", "exp", "poisson", "binom", "likert")
dnames = c("Normal", "Log-normal", "Exponential", "Poisson", "Binomial", "Ordinal (5 levels)")
methods = c("RNK", "INT", "VDW", "KWF")
palette = c("#E69F00", "#009E73", "#FF70AB", "#888888")

df <- read_data(prefix, alpha, effectType = 1, distributions, methods = methods)
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))

plotly_error_by_design_2(df, xlab = "magnitude of main effect", var = "rateX2", xvar = "effectX1", max = 8.1, nticks=8, cbPalette = palette)
```
Type I error rates ($\alpha = .05$) for the **main effect of $X_2$** as a function of the magnitude $a_1$ of the main effect of $X_1$ ($n = 20$)
:::

**Type I error rates: Interactions**. @fig-vdWaerden-designs-interaction-1 presents the Type I error rates for the interaction in the presence of a single main effect. Again, the error rates of VDW and KWF decrease rapidly, now in both the between-subjects and mixed designs. We also observe inflation of the error rates of RNK and INT for large effects under discrete distributions.

::: {#fig-vdWaerden-designs-interaction-1}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
df <- read_data(prefix, alpha, effectType = 2, distributions, methods = methods)
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))

plotly_error_by_design_2(df, xlab = "magnitude of main effect", var = "rateX1X2", xvar = "effectX2", max = 8.1, nticks=8, cbPalette = palette)
```
Type I error rates ($\alpha = .05$) for the **interaction** $X_1 \times X_2$ as a function of the magnitude $a_2$ of the main effect of $X_2$ ($n = 20$) 
:::

@fig-vdWaerden-designs-interaction-2 shows the results when both $a_1$ and $a_2$ increase. In these settings, all four methods struggle as effect magnitudes grow, though their behavior varies across distributions and experimental designs. Depending on the configuration, the methods either inflate positive rates or deflate them below nominal levels. INT appears to be the most stable method for continuous distributions, but its positive rates increase more rapidly under discrete distributions.    

::: {#fig-vdWaerden-designs-interaction-2}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
df <- read_data(prefix, alpha, effectType = 0, distributions, methods = methods)
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))
plotly_error_by_design_2(df, xlab = "magnitude of main effects", ytitle = 'Positives (%)', var = "rateX1X2", xvar = "effectX1", max = 104, nticks=8, cbPalette = palette)
```
Positive rates ($\alpha = .05$) for the **interaction** $X_1 \times X_2$ as a function of the magnitudes $a_1 = a_2$ of the main effects of $X_1$ and $X_2$ ($n = 20$). *Note: These values correspond to Type I error rates under the null hypothesis $a_{12} = 0$; alternative definitions of the null hypothesis may lead to different results.* 
:::

**Power: Main effects**. We examine how power is affected by increasing the magnitude of the effect on the second factor. As shown in @fig-vdWaerden-power-main-X1 and @fig-vdWaerden-power-main-X2, the power of all methods decreases, but KWF and VDW appear especially problematic under the between-subjects design (across all distributions) and the mixed design (for the log-normal and exponential distributions). INT once again emerges as the best-performing method.

::: {#fig-vdWaerden-power-main-X1}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
alpha <- .05
prefix <- "Power_vdWaerden_multieffect"

df <- read_data(prefix, alpha, effectType = -1, distributions, methods = methods)
df <- df[df$effectX1 == 0.6,]
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))

plotly_error_by_design_2(df, xlab = "magnitude of main effect", var = "rateX1", xvar = "effectX2", ytitle ="Power (%)", max = 104, nticks=6, cbPalette = palette)
```
Power ($\alpha = .05$) for detecting the **main effect of $X_1$** ($a_1 = 0.8$) as a function of the magnitude of effect $a_2$ of the main effect of $X_2$ ($n=20$).
:::

::: {#fig-vdWaerden-power-main-X2}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
df <- read_data(prefix, alpha, effectType = -1, distributions, methods = methods)
df <- df[df$effectX2 == 0.6,]
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))

plotly_error_by_design_2(df, xlab = "magnitude of main effect", var = "rateX2", xvar = "effectX1", ytitle ="Power (%)", max = 104, nticks=6, cbPalette = palette)
```
Power ($\alpha = .05$) for detecting the **main effect of $X_2$** ($a_2 = 0.8$) as a function of the magnitude $a_1$ of the main effect of $X_1$ ($n=20$).
:::


**Power: Interactions**. @fig-vdWaerden-power-interaction-X1 and @fig-vdWaerden-power-interaction-X1 show how the power for detecting the interaction effect is affected by the presence of a main effect. We observe that the power of all methods decreases as $a_1$ or $a_2$ increase, but this decline is substantially more pronounced for KWF and VDW, particularly in the between-subjects and mixed designs.

::: {#fig-vdWaerden-power-interaction-X1}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
alpha <- .05
prefix <- "Power_vdWaerden_multieffect"

df <- read_data(prefix, alpha, effectType = -1, distributions, methods = methods)
df <- df[df$effectX1X2 > 0 & df$effectX2 == 0,]
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))

plotly_error_by_design_2(df, xlab = "magnitude of main effect", var = "rateX1X2", xvar = "effectX1", ytitle ="Power (%)", max = 104, nticks=6, cbPalette = palette)
```
Power ($\alpha = .05$) for detecting the **interaction effect** ($a_{12} = 1.5$) as a function of the magnitude of effect $a_2$ of the main effect of $X_2$ ($n=20$).
:::

::: {#fig-vdWaerden-power-interaction-X2}
```{r, echo=FALSE, fig.height=3.3, fig.width = 9, warning=FALSE}
df <- read_data(prefix, alpha, effectType = -1, distributions, methods = methods)
df <- df[df$effectX1X2 > 0 & df$effectX1 == 0,]
df <- reshape_by_design(df, dnames, effectvars = c("effectX1","effectX2","effectX1X2"))

plotly_error_by_design_2(df, xlab = "magnitude of main effect", var = "rateX1X2", xvar = "effectX2", ytitle ="Power (%)", max = 104, nticks=6, cbPalette = palette)
```
Power ($\alpha = .05$) for detecting the **interaction effect** ($a_{12} = 1.5$) as a function of the magnitude $a_2$ of the main effect of $X_2$ ($n=20$).
:::


### Conclusion
Our results do not support the conclusions of Lüpsen [-@luepsen:2018; -@luepsen:2023]. The generalized nonparametric tests have serious limitations across a wide range of scenarios. Although these methods sometimes lead to lower Type I error rates, this behavior is largely due to a substantial loss of statistical power when other effects are present. Consequently, we do not recommend the use of these methods.
